defaults:
    - _self_
    - encoder: gru
    - decoder: gru

model:
    _target_: model.model.Seq2Seq
    encoder: ${encoder}
    decoder: ${decoder}
    teacher_forcing_ratio: ${teacher_forcing_ratio}
    max_length: ${max_length}
    sos_token: ${sos_token}
    eos_token: ${eos_token}
    pad_token: ${pad_token}

decoder:
    use_attention: false

optimizer:
    _target_: torch.optim.SGD
    lr: ${lr}

early_stopping:
    _target_: utils.patience.Patience
    patience: 3
    mode: min
    metric: loss

batch_size: 1
lr: 0.1
epochs: 1000
hidden_size: 512

print_every: 5000
teacher_forcing_ratio: 0.5
plot_every: 100
sos_token: 0
eos_token: 1
unk_token: 2
pad_token: 3
max_length: 15
l1: fra
l2: eng
test_size: 0.1
val_size: 0.1
reverse: true
max_grad_norm: 1
dropout: 0.1

seed: 42
device: null  # null means that the device will be selected automatically
name: null  # null means that the name will be generated automatically
group: null  # null means that the group will be generated automatically

wandb:
    entity: crutch
    project: "Seq2Seq model for machine translation"
